{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1:**"
      ],
      "metadata": {
        "id": "F0eanPZYkiYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHxrjHpkgpUu",
        "outputId": "06338a13-4a9f-4603-e205-dc433de70174"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.42)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.43.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing packages\n",
        "import wandb\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize WandB project\n",
        "wandb.init(project=\"set-1\")\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Define class names for Fashion MNIST dataset\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# Plotting a figure from each class\n",
        "plt.figure(figsize=[12, 5])\n",
        "images = []\n",
        "captions = []\n",
        "\n",
        "# Loop through each class\n",
        "for i, class_name in enumerate(class_names):\n",
        "    # Find the first image of the current class\n",
        "    index = np.argmax(y_train == i)\n",
        "    image = x_train[index]\n",
        "\n",
        "    # Plot the image\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(class_name)\n",
        "\n",
        "    # Append the image and its caption to lists\n",
        "    images.append(image)\n",
        "    captions.append(class_name)\n",
        "\n",
        "# Log images to WandB\n",
        "wandb.log({\"Fashion MNIST Images\": [wandb.Image(img, caption=caption) for img, caption in zip(images, captions)]})\n",
        "\n",
        "plt.show()  # Show the plot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "359P451DixOk",
        "outputId": "2e5329e7-65ee-4d2b-ebb6-665c06c92df7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma22c019\u001b[0m (\u001b[33mbeliever12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240320_170132-dsre6z8s</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/believer12/set-1/runs/dsre6z8s' target=\"_blank\">absurd-dew-140</a></strong> to <a href='https://wandb.ai/believer12/set-1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/believer12/set-1' target=\"_blank\">https://wandb.ai/believer12/set-1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/believer12/set-1/runs/dsre6z8s' target=\"_blank\">https://wandb.ai/believer12/set-1/runs/dsre6z8s</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2:**"
      ],
      "metadata": {
        "id": "mHVZIQ2Flppv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Load Fashion-MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Flatten images\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Split data into training and validation sets\n",
        "x_train, x_val, y_train_encoded, y_val_encoded = train_test_split(x_train, y_train_encoded, test_size=0.1, random_state=42)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_layers, num_neurons, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.num_neurons = num_neurons\n",
        "        self.output_size = output_size\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self.activations = [self.relu] * (self.hidden_layers) + [self.softmax]\n",
        "\n",
        "        # Initialize weights and biases for hidden layers\n",
        "        for i in range(self.hidden_layers):\n",
        "            if i == 0:\n",
        "                self.weights.append(np.random.randn(self.input_size, self.num_neurons))\n",
        "            else:\n",
        "                self.weights.append(np.random.randn(self.num_neurons, self.num_neurons))\n",
        "            self.biases.append(np.zeros((1, self.num_neurons)))\n",
        "\n",
        "        # Initialize weights and biases for output layer\n",
        "        self.weights.append(np.random.randn(self.num_neurons, self.output_size))\n",
        "        self.biases.append(np.zeros((1, self.output_size)))\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exp_values = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x\n",
        "        for i in range(self.hidden_layers + 1):\n",
        "            output = np.dot(output, self.weights[i]) + self.biases[i]\n",
        "            output = self.activations[i](output)\n",
        "        return output\n",
        "\n",
        "    def backward(self, x, y, lr):\n",
        "        # Forward pass\n",
        "        layer_outputs = [x]\n",
        "        for i in range(self.hidden_layers + 1):\n",
        "            layer_outputs.append(np.dot(layer_outputs[i], self.weights[i]) + self.biases[i])\n",
        "            layer_outputs[i+1] = self.activations[i](layer_outputs[i+1])\n",
        "\n",
        "        # Backward pass\n",
        "        errors = [None] * (self.hidden_layers + 1)\n",
        "        errors[-1] = layer_outputs[-1] - y\n",
        "        for i in range(self.hidden_layers, 0, -1):\n",
        "            errors[i-1] = np.dot(errors[i], self.weights[i].T) * (layer_outputs[i] > 0)\n",
        "\n",
        "        # Update weights and biases\n",
        "        for i in range(self.hidden_layers + 1):\n",
        "            self.weights[i] -= lr * np.dot(layer_outputs[i].T, errors[i])\n",
        "            self.biases[i] -= lr * np.sum(errors[i], axis=0)\n",
        "\n",
        "    def train(self, x_train, y_train, x_val, y_val, lr, epochs, batch_size):\n",
        "        num_batches = len(x_train) // batch_size\n",
        "        for epoch in range(1, epochs+1):\n",
        "            for batch in range(num_batches):\n",
        "                start = batch * batch_size\n",
        "                end = start + batch_size\n",
        "                x_batch = x_train[start:end]\n",
        "                y_batch = y_train[start:end]\n",
        "                self.backward(x_batch, y_batch, lr)\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            val_pred = self.predict(x_val)\n",
        "            val_loss = self.cross_entropy_loss(val_pred, y_val)\n",
        "            val_acc = accuracy_score(np.argmax(y_val, axis=1), np.argmax(val_pred, axis=1))\n",
        "            print(f\"Epoch {epoch}/{epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def cross_entropy_loss(self, y_pred, y_true):\n",
        "        epsilon = 1e-15\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
        "\n",
        "# Model parameters\n",
        "input_size = x_train.shape[1]\n",
        "hidden_layers = 2\n",
        "num_neurons = 256\n",
        "output_size = 10\n",
        "lr = 0.001\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# Create and train the model\n",
        "model = NeuralNetwork(input_size, hidden_layers, num_neurons, output_size)\n",
        "model.train(x_train, y_train_encoded, x_val, y_val_encoded, lr, epochs, batch_size)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_pred = model.predict(x_test)\n",
        "test_acc = accuracy_score(np.argmax(y_test_encoded, axis=1), np.argmax(test_pred, axis=1))\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CynVtcF8NeCS",
        "outputId": "e46b1c60-b809-4ff8-8984-42d717eb0c9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 2/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 3/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 4/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 5/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 6/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 7/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 8/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 9/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Epoch 10/10, Validation Loss: 2.3025, Validation Accuracy: 0.1035\n",
            "Test Accuracy: 0.0997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3:**"
      ],
      "metadata": {
        "id": "2N4o3ifcsXvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Functions and their Derivatives**"
      ],
      "metadata": {
        "id": "TT79RTidvxNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Sigmoid():\n",
        "    def __init__(self, c=1, b=0):\n",
        "        self.c = c\n",
        "        self.b = b\n",
        "\n",
        "    def value(self, x):\n",
        "        val = 1 + np.exp(-self.c*(x + self.b))\n",
        "        return 1/val\n",
        "\n",
        "    def diff(self, x, remove=False):\n",
        "        y = self.value(x)\n",
        "        if remove==True:\n",
        "            y = y[:-1,:]\n",
        "        val = self.c*y*(1-y)\n",
        "        return val\n",
        "\n",
        "class Tanh():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def value(self, x):\n",
        "        num = np.exp(x) - np.exp(-x)\n",
        "        denom = np.exp(x) + np.exp(-x)\n",
        "        return num/denom\n",
        "\n",
        "    def diff(self, x):\n",
        "        y = self.value(x)\n",
        "        val = 1 - y**2\n",
        "        return val\n",
        "\n",
        "class Relu():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def value(self, x):\n",
        "        val = x\n",
        "        val[val<0] = 0\n",
        "        return val\n",
        "\n",
        "    def diff(self, x):\n",
        "        val = np.ones(x.shape)\n",
        "        val[val<=0] = 0\n",
        "        return val\n",
        "\n",
        "class Softmax():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def value(self, x):\n",
        "        # Numerically stable softmax\n",
        "        exps = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=0, keepdims=True)\n",
        "\n",
        "    def diff(self, x):\n",
        "        # Compute the softmax function\n",
        "        softmax_output = self.value(x)\n",
        "        # Compute the Jacobian matrix of the softmax function\n",
        "        n = softmax_output.shape[1]\n",
        "        jacobian_matrix = np.zeros((n, n, n))\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if i == j:\n",
        "                    jacobian_matrix[i, j, :] = softmax_output[:, i] * (1 - softmax_output[:, j])\n",
        "                else:\n",
        "                    jacobian_matrix[i, j, :] = -softmax_output[:, i] * softmax_output[:, j]\n",
        "        return jacobian_matrix.sum(axis=1)\n",
        "\n",
        "map_activations = {\"Sigmoid\":Sigmoid(), \"Tanh\":Tanh(), \"Relu\":Relu(), \"Softmax\":Softmax()}"
      ],
      "metadata": {
        "id": "H84FSPgkw7PP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layers**"
      ],
      "metadata": {
        "id": "R9vr3Qp9y3Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Layer():\n",
        "    def __init__(self, name, size, activation=None):\n",
        "        self.name = name\n",
        "        self.size = size\n",
        "        self.activation = activation\n",
        "        self.type = self.__class__.__name__\n",
        "\n",
        "    def __repr__(self):\n",
        "        activation_info = f\"; Activation: {self.activation}\" if self.activation else \"\"\n",
        "        return f\"{self.type} - of Size: {self.size}\" + activation_info\n",
        "\n",
        "\n",
        "class Input(Layer):\n",
        "    def __init__(self, data, name=None, size=None):\n",
        "        super().__init__(name, size)\n",
        "        self.data = data\n",
        "        self.a = self.data\n",
        "        self.a_val = None\n",
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, size, activation=None, name=None):\n",
        "        name = name if name else f\"Dense_{np.random.randint(1e6)}\"\n",
        "        super().__init__(name, size, activation)"
      ],
      "metadata": {
        "id": "YVKLDGHCy1Vw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizers**"
      ],
      "metadata": {
        "id": "pqLBeUePyTzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Optimizer():\n",
        "    def __init__(self, **kwargs):\n",
        "        self.params = kwargs\n",
        "        self.initialize_params()\n",
        "\n",
        "    def initialize_params(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def update(self, grad):\n",
        "        pass\n",
        "\n",
        "class Normal(Optimizer):\n",
        "    def __init__(self, eta):\n",
        "        self.eta = eta\n",
        "\n",
        "    def update(self, grad):\n",
        "        return self.eta * grad\n",
        "\n",
        "class Momentum(Optimizer):\n",
        "    def initialize_params(self):\n",
        "        self.v = 0\n",
        "\n",
        "    def update(self, grad):\n",
        "        self.v = self.params['gamma'] * self.v + self.params['eta'] * grad\n",
        "        return self.v\n",
        "\n",
        "class Nesterov(Optimizer):\n",
        "    def initialize_params(self):\n",
        "        self.v = 0\n",
        "\n",
        "    def update(self, grad):\n",
        "        self.v = self.params['gamma'] * self.v + self.params['eta'] * grad\n",
        "        return self.params['gamma'] * self.v + self.params['eta'] * grad\n",
        "\n",
        "class AdaGrad(Optimizer):\n",
        "    def initialize_params(self):\n",
        "        self.v = 0\n",
        "\n",
        "    def update(self, grad):\n",
        "        self.v += grad ** 2\n",
        "        return (self.params['eta'] / (self.v + self.params['eps']) ** 0.5) * grad\n",
        "\n",
        "class RMSProp(Optimizer):\n",
        "    def initialize_params(self):\n",
        "        self.v = 0\n",
        "\n",
        "    def update(self, grad):\n",
        "        self.v = self.params['beta'] * self.v + (1 - self.params['beta']) * grad ** 2\n",
        "        return (self.params['eta'] / (self.v + self.params['eps']) ** 0.5) * grad\n",
        "\n",
        "class Adam(Optimizer):\n",
        "    def initialize_params(self):\n",
        "        self.m = 0\n",
        "        self.v = 0\n",
        "        self.iter = 1\n",
        "\n",
        "    def update(self, grad):\n",
        "        self.m = self.params['beta1'] * self.m + (1 - self.params['beta1']) * grad\n",
        "        self.v = self.params['beta2'] * self.v + (1 - self.params['beta2']) * grad ** 2\n",
        "        m_cap = self.m / (1 - self.params['beta1'] ** self.iter)\n",
        "        v_cap = self.v / (1 - self.params['beta2'] ** self.iter)\n",
        "        self.iter += 1\n",
        "        return (self.params['eta'] / (v_cap + self.params['eps']) ** 0.5) * m_cap\n",
        "\n",
        "class Nadam(Adam):\n",
        "    def update(self, grad):\n",
        "        self.m = self.params['beta1'] * self.m + (1 - self.params['beta1']) * grad\n",
        "        self.v = self.params['beta2'] * self.v + (1 - self.params['beta2']) * grad ** 2\n",
        "        m_cap = self.m / (1 - self.params['beta1'] ** self.iter)\n",
        "        v_cap = self.v / (1 - self.params['beta2'] ** self.iter)\n",
        "        update = self.params['beta1'] * m_cap + ((1 - self.params['beta1']) / (1 - self.params['beta1'] ** self.iter)) * grad\n",
        "        self.iter += 1\n",
        "        return (self.params['eta'] / (v_cap + self.params['eps']) ** 0.5) * update"
      ],
      "metadata": {
        "id": "SGXfO7llyRHj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss**"
      ],
      "metadata": {
        "id": "mYdHkVAL1X4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class CrossEntropy:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calc_loss(self, t, y):\n",
        "        self.t = t\n",
        "        self.y = y\n",
        "        loss = -np.sum(t * np.log(y))\n",
        "        return loss\n",
        "\n",
        "    def diff(self, t_batch, y_batch):\n",
        "        grad = -t_batch / y_batch\n",
        "        return grad\n",
        "\n",
        "class SquaredError:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def calc_loss(self, t, y):\n",
        "        self.t = t\n",
        "        self.y = y\n",
        "        loss = np.sum((t - y) ** 2)\n",
        "        return loss\n",
        "\n",
        "    def diff(self, t_batch, y_batch):\n",
        "        grad = -(t_batch - y_batch)\n",
        "        return grad\n"
      ],
      "metadata": {
        "id": "hxV4f63D1cBh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper**"
      ],
      "metadata": {
        "id": "-C8j3a_u13sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class OneHotEncoder:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, y, num_classes):\n",
        "        self.y = y\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def transform(self):\n",
        "        transformed = np.eye(self.num_classes)[self.y].T\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, y, num_classes):\n",
        "        self.fit(y, num_classes)\n",
        "        return self.transform()\n",
        "\n",
        "    def inverse_transform(self, y):\n",
        "        y_class = np.argmax(y, axis=0)\n",
        "        return y_class\n",
        "\n",
        "\n",
        "class MinMaxScaler:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.min = np.min(X, axis=0)\n",
        "        self.max = np.max(X, axis=0)\n",
        "\n",
        "    def transform(self, X):\n",
        "        transformed = (X - self.min) / (self.max - self.min)\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, X):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)"
      ],
      "metadata": {
        "id": "n-QNtvRy18Gc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural NetworK**"
      ],
      "metadata": {
        "id": "igPTssd12R9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layers, batch_size, optimizer, initialization, epochs, t, loss, X_val=None, t_val=None, use_wandb=False, optim_params=None):\n",
        "        self.layers = layers\n",
        "        self.batch_size = batch_size\n",
        "        self.initialization = initialization\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.t = t\n",
        "        self.t_val = t_val\n",
        "        self.loss = loss\n",
        "        self.use_wandb = use_wandb\n",
        "        self.num_batches = math.ceil(t.shape[1] / batch_size)\n",
        "        self.X_val = X_val\n",
        "        self.param_init(optimizer, optim_params)\n",
        "\n",
        "\n",
        "    def param_init(self, optimizer, optim_params):\n",
        "      size_prev = self.layers[0].data.shape[1]\n",
        "      for layer in self.layers[1:]:\n",
        "        layer.W_size = (layer.size, size_prev)\n",
        "        size_prev = layer.size\n",
        "        layer.W_optimizer = deepcopy(optimizer(eta=0.01))\n",
        "        layer.b_optimizer = deepcopy(optimizer(eta=0.01))\n",
        "      if optim_params:\n",
        "        for layer, params in zip(self.layers[1:], optim_params):\n",
        "            layer.W_optimizer.eta = params[0]\n",
        "            layer.b_optimizer.eta = params[1]\n",
        "      if self.initialization == \"RandomNormal\":\n",
        "        for layer in self.layers[1:]:\n",
        "            layer.W = np.random.normal(loc=0, scale=1.0, size=layer.W_size)\n",
        "            layer.b = np.zeros((layer.W_size[0], 1))\n",
        "      elif self.initialization == \"XavierUniform\":\n",
        "        for layer in self.layers[1:]:\n",
        "            limit = np.sqrt(6 / (layer.W_size[0] + layer.W_size[1]))\n",
        "            layer.W = np.random.uniform(-limit, limit, layer.W_size)\n",
        "            layer.b = np.zeros((layer.W_size[0], 1))\n",
        "\n",
        "\n",
        "\n",
        "# In the NeuralNetwork class, update the forward_propagation method\n",
        "    def forward_propagation(self):\n",
        "      for i in range(1, len(self.layers)):\n",
        "        self.layers[i].h = self.layers[i].W @ self.layers[i-1].a - self.layers[i].b\n",
        "        self.layers[i].a = self.layers[i].activation.value(self.layers[i].h)\n",
        "        if self.t_val is not None:\n",
        "            self.layers[i].h_val = self.layers[i].W @ self.layers[i-1].a_val - self.layers[i].b\n",
        "            self.layers[i].a_val = self.layers[i].activation.value(self.layers[i].h_val)\n",
        "\n",
        "        if self.loss_type == \"CrossEntropy\":\n",
        "          self.layers[-1].y = Softmax().value(self.layers[-1].a).T  # Transpose y here\n",
        "          if self.t_val is not None:\n",
        "            self.layers[-1].y_val = Softmax().value(self.layers[-1].a_val).T\n",
        "      else:\n",
        "        self.layers[-1].y = self.layers[-1].a.T  # Transpose y here\n",
        "        if self.t_val is not None:\n",
        "            self.layers[-1].y_val = self.layers[-1].a_val.T\n",
        "\n",
        "    def check_test(self, X_test, t_test):\n",
        "        self.layers[0].a_test = X_test\n",
        "        for i in range(1, len(self.layers)):\n",
        "            self.layers[i].h_test = self.layers[i].W @ self.layers[i-1].a_test - self.layers[i].b\n",
        "            self.layers[i].a_test = self.layers[i].activation.value(self.layers[i].h_test)\n",
        "\n",
        "        if self.loss == \"CrossEntropy\":\n",
        "            self.layers[-1].y_test = Softmax().value(self.layers[-1].a_test)\n",
        "        else:\n",
        "            self.layers[-1].y_test = self.layers[-1].a_test\n",
        "\n",
        "        loss_test = self.loss.calc_loss(t_test, self.layers[-1].y_test)\n",
        "\n",
        "        encoder = OneHotEncoder()\n",
        "        y_tmp = encoder.inverse_transform(self.layers[-1].y_test)\n",
        "        t_tmp = encoder.inverse_transform(t_test)\n",
        "        acc_test = np.sum(y_tmp == t_tmp)\n",
        "        return acc_test, loss_test, y_tmp\n",
        "\n",
        "    def backward_propagation(self):\n",
        "        self.eta_hist = []\n",
        "        self.loss_hist = []\n",
        "        self.accuracy_hist = []\n",
        "        self.loss_hist_val = []\n",
        "        self.accuracy_hist_val = []\n",
        "        flag = 0\n",
        "\n",
        "        for ep in tqdm(range(self.epochs)):\n",
        "            self.eta_hist.append(self.layers[-1].W_optimizer.eta)\n",
        "            self.loss_hist.append(self.loss.calc_loss(self.t, self.layers[-1].y))\n",
        "            train_acc, val_acc = self.get_accuracy(validation=True)\n",
        "            self.accuracy_hist.append(train_acc)\n",
        "            self.loss_hist_val.append(self.loss.calc_loss(self.t_val, self.layers[-1].y_val))\n",
        "            self.accuracy_hist_val.append(val_acc)\n",
        "\n",
        "            if self.use_wandb:\n",
        "                wandb.log({\n",
        "                    \"step\": ep,\n",
        "                    \"loss:\": self.loss_hist[-1] / self.t.shape[1],\n",
        "                    \"accuracy\": self.accuracy_hist[-1] / self.t.shape[1],\n",
        "                    \"val_loss\": self.loss_hist_val[-1] / self.t_val.shape[1],\n",
        "                    \"val_accuracy\": self.accuracy_hist_val[-1] / self.t_val.shape[1]\n",
        "                })\n",
        "\n",
        "            for batch in range(self.num_batches):\n",
        "                t_batch = self.t[:, batch * self.batch_size:(batch + 1) * self.batch_size]\n",
        "                y_batch = self.layers[-1].y[:, batch * self.batch_size:(batch + 1) * self.batch_size]\n",
        "                self.y_batch = y_batch\n",
        "                self.t_batch = t_batch\n",
        "\n",
        "                if flag == 1:\n",
        "                    break\n",
        "\n",
        "                if flag == 1:\n",
        "                    break\n",
        "\n",
        "    def describe(self):\n",
        "        print(\"Model with the following layers:\")\n",
        "        for layer in self.layers:\n",
        "            print(layer)\n",
        "        print(\"Loss:\", self.loss)\n",
        "        print(\"Epochs:\", self.epochs)\n",
        "        print(\"Batch Size:\", self.batch_size)\n",
        "        print(\"Optimizer:\", self.optimizer)\n",
        "        print(\"Initialization:\", self.initialization)\n",
        "\n",
        "    def get_accuracy(self, validation=False, print_vals=False):\n",
        "        encoder = OneHotEncoder()\n",
        "        t_train = encoder.inverse_transform(self.t)\n",
        "        y_train = encoder.inverse_transform(self.layers[-1].y)\n",
        "        acc_train = np.sum(t_train == y_train)\n",
        "        if print_vals:\n",
        "            print(\"Train Accuracy:\", acc_train)\n",
        "\n",
        "        if validation:\n",
        "            t_val = encoder.inverse_transform(self.t_val)\n",
        "            y_val = encoder.inverse_transform(self.layers[-1].y_val)\n",
        "            acc_val = np.sum(t_val == y_val)\n",
        "            if print_vals:\n",
        "                print(\"Validation Accuracy:\", acc_val)\n",
        "            return acc_train, acc_val\n",
        "        return acc_train\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.epochs):\n",
        "            # Perform forward propagation\n",
        "            self.forward_propagation()\n",
        "\n",
        "            # Perform backward propagation\n",
        "            self.backward_propagation()\n",
        "\n",
        "            # Optionally print or log metrics\n",
        "            print(f\"Epoch {epoch + 1}/{self.epochs} - Loss: {self.loss_hist[-1]}\")\n",
        "\n",
        "        # Optionally, return or log final metrics after training\n",
        "        print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "S2mtLm9LzCYi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoder**"
      ],
      "metadata": {
        "id": "zGbADqRC6VjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotEncoder:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, y, num_classes):\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def transform(self, y):\n",
        "        transformed = np.eye(self.num_classes)[y].T\n",
        "        return transformed\n",
        "\n",
        "    def fit_transform(self, y, num_classes):\n",
        "        self.fit(y, num_classes)\n",
        "        return self.transform(y)\n",
        "\n",
        "    def inverse_transform(self, y):\n",
        "        y_class = np.argmax(y, axis=0)\n",
        "        return y_class\n"
      ],
      "metadata": {
        "id": "HKuC5Kmj6LVc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Code:**"
      ],
      "metadata": {
        "id": "q0sdCK3l2zzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
        "print(\"Done!\")\n",
        "\n",
        "# Preprocess data\n",
        "scaler = MinMaxScaler()\n",
        "encoder = OneHotEncoder()\n",
        "X_train_scaled = scaler.fit_transform(x_train.reshape(x_train.shape[0], -1))\n",
        "X_val_scaled = scaler.transform(x_val.reshape(x_val.shape[0], -1))\n",
        "X_test_scaled = scaler.transform(x_test.reshape(x_test.shape[0], -1))\n",
        "\n",
        "t_train = encoder.fit_transform(y_train, 10)\n",
        "t_val = encoder.transform(y_val)\n",
        "t_test = encoder.transform(y_test)\n",
        "\n",
        "# Limit dataset size for faster training\n",
        "X_train_scaled = X_train_scaled[:, :2000]\n",
        "X_val_scaled = X_val_scaled[:, :500]\n",
        "X_test_scaled = X_test_scaled[:, :10000]  # Adjusted the size for testing data\n",
        "\n",
        "# Define neural network architecture\n",
        "layers = [\n",
        "    Input(data=X_train_scaled),  # Input layer with appropriate size\n",
        "    Dense(size=64, activation=Sigmoid(), name=\"HiddenLayer\"),\n",
        "    Dense(size=10, activation=Softmax(), name=\"OutputLayer\")  # Output layer with appropriate size\n",
        "]\n",
        "\n",
        "# Initialize and train the neural network\n",
        "model = NeuralNetwork(\n",
        "    layers=layers,\n",
        "    batch_size=2000,\n",
        "    optimizer=Normal,\n",
        "    initialization=\"RandomNormal\",\n",
        "    epochs=100,\n",
        "    t=t_train,\n",
        "    X_val=X_val_scaled,\n",
        "    t_val=t_val,\n",
        "    loss=CrossEntropy(),  # Specify the loss function\n",
        "    use_wandb=False\n",
        ")\n",
        "model.train()\n",
        "\n",
        "# Evaluate the model\n",
        "acc_train, loss_train = model.evaluate(X_train_scaled, t_train)\n",
        "acc_val, loss_val = model.evaluate(X_val_scaled, t_val)\n",
        "acc_test, loss_test = model.evaluate(X_test_scaled, t_test)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"=\"*50)\n",
        "print(\"Training Data\")\n",
        "print(\"Fraction Correctly classified:\", acc_train)\n",
        "print(\"Loss:\", loss_train)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Validation Data\")\n",
        "print(\"Fraction Correctly classified:\", acc_val)\n",
        "print(\"Loss:\", loss_val)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Testing Data\")\n",
        "print(\"Fraction Correctly classified:\", acc_test)\n",
        "print(\"Loss:\", loss_test)\n",
        "\n",
        "# Plot training and validation metrics\n",
        "plt.figure()\n",
        "plt.plot(np.array(model.accuracy_hist_val) / 500, label=\"Training Accuracy\")\n",
        "plt.plot(np.array(model.accuracy_hist) / 2000, label=\"Validation Accuracy\")\n",
        "plt.title(\"Accuracy of the Model\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(model.loss_hist) / 2000, label=\"Training Loss\")\n",
        "plt.plot(np.array(model.loss_hist_val) / 500, label=\"Validation Loss\")\n",
        "plt.title(\"Loss of the Model\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ukeRhuDs7ffE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4:**"
      ],
      "metadata": {
        "id": "yYkWK-duvKxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "    print(\"Done!\")\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "def preprocess_data(x_train, y_train, x_val, y_val, x_test, y_test):\n",
        "    X_scaled = x_train / 255\n",
        "    X_val_scaled = x_val / 255\n",
        "    X_test_scaled = x_test / 255\n",
        "\n",
        "    X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1] * X_scaled.shape[2]).T\n",
        "    X_val_scaled = X_val_scaled.reshape(X_val_scaled.shape[0], X_val_scaled.shape[1] * X_val_scaled.shape[2]).T\n",
        "    X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1] * X_test_scaled.shape[2]).T\n",
        "\n",
        "    encoder = OneHotEncoder()\n",
        "    t = encoder.fit_transform(y_train, 10)\n",
        "    t_val = encoder.fit_transform(y_val, 10)\n",
        "    t_test = encoder.fit_transform(y_test, 10)\n",
        "    print(\"Done!\")\n",
        "\n",
        "    X_scaled = X_scaled[:, :21000]\n",
        "    X_test_scaled = X_test_scaled[:, :9000]\n",
        "    t = t[:, :21000]\n",
        "    t_test = t_test[:, :9000]\n",
        "\n",
        "    return X_scaled, t, X_val_scaled, t_val, X_test_scaled, t_test\n",
        "\n",
        "def define_network(X_scaled, t, X_val_scaled, t_val):\n",
        "    layers = [\n",
        "        Input(data=X_scaled),\n",
        "        Dense(size=64, activation=Sigmoid(), name=\"HiddenLayer\"),\n",
        "        Dense(size=10, activation=Softmax(), name=\"OutputLayer\")\n",
        "    ]\n",
        "    return NeuralNetwork(\n",
        "        layers=layers,\n",
        "        batch_size=2000,\n",
        "        optimizer=Normal,\n",
        "        initialization=\"RandomNormal\",\n",
        "        epochs=100,\n",
        "        t=t,\n",
        "        X_val=X_val_scaled,\n",
        "        t_val=t_val,\n",
        "        loss=CrossEntropy(),\n",
        "        use_wandb=False\n",
        "    )\n",
        "\n",
        "def train_and_evaluate(model, X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test):\n",
        "    model.train()\n",
        "    acc_train, loss_train = model.evaluate(X_train_scaled, t_train)\n",
        "    acc_val, loss_val = model.evaluate(X_val_scaled, t_val)\n",
        "    acc_test, loss_test = model.evaluate(X_test_scaled, t_test)\n",
        "    return acc_train, loss_train, acc_val, loss_val, acc_test, loss_test\n",
        "\n",
        "def train_nn(config):\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = load_data()\n",
        "    X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test = preprocess_data(\n",
        "        x_train, y_train, x_val, y_val, x_test, y_test\n",
        "    )\n",
        "    model = define_network(X_train_scaled, t_train, X_val_scaled, t_val)\n",
        "    acc_train, loss_train, acc_val, loss_val, acc_test, loss_test = train_and_evaluate(\n",
        "        model, X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test\n",
        "    )\n",
        "    return acc_train, loss_train, acc_val, loss_val, acc_test, loss_test\n",
        "\n",
        "sweep_config = {\n",
        "    \"name\": \"complete-sweep\",\n",
        "    \"method\": \"grid\",\n",
        "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "    \"parameters\": {\n",
        "        \"num_epochs\": {\"values\": [10, 50]},\n",
        "        \"size_hidden_layer\": {\"values\": [32, 64, 128]},\n",
        "        \"optimizer\": {\"values\": [\"Normal\", \"Momentum\", \"AdaGrad\", \"RMSProp\", \"Adam\", \"Nadam\"]},\n",
        "        \"batch_size\": {\"values\": [128, 1024, 60000]},\n",
        "        \"weight_init\": {\"values\": [\"RandomNormal\", \"XavierUniform\"]},\n",
        "        \"activation\": {\"values\": [\"Sigmoid\", \"Tanh\", \"Relu\"]},\n",
        "        \"loss\": {\"values\": [\"CrossEntropy\", \"SquaredError\"]}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"set-1\")\n",
        "wandb.agent(sweep_id, function=train_nn)"
      ],
      "metadata": {
        "id": "wkYq_n5GlN3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 7:**"
      ],
      "metadata": {
        "id": "bVFWLI7ym7rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import wandb\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "    print(\"Done!\")\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "def preprocess_data(x_train, y_train, x_val, y_val, x_test, y_test):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x_train)\n",
        "    X_scaled = x_train / 255\n",
        "    X_val_scaled = x_val / 255\n",
        "    X_test_scaled = x_test / 255\n",
        "\n",
        "    X_scaled = X_scaled.reshape(X_scaled.shape[0], -1).T\n",
        "    X_val_scaled = X_val_scaled.reshape(X_val_scaled.shape[0], -1).T\n",
        "    X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], -1).T\n",
        "\n",
        "    encoder = OneHotEncoder()\n",
        "    t = encoder.fit_transform(y_train, 10)\n",
        "    t_val = encoder.fit_transform(y_val, 10)\n",
        "    t_test = encoder.fit_transform(y_test, 10)\n",
        "    print(\"Done!\")\n",
        "\n",
        "    X_scaled = X_scaled[:, :21000]\n",
        "    X_test_scaled = X_test_scaled[:, :9000]\n",
        "    t = t[:, :21000]\n",
        "    t_test = t_test[:, :9000]\n",
        "\n",
        "    return X_scaled, t, X_val_scaled, t_val, X_test_scaled, t_test\n",
        "\n",
        "def define_network(X_scaled, t, X_val_scaled, t_val):\n",
        "    layers = [\n",
        "        Input(data=X_scaled),\n",
        "        Dense(size=64, activation=Sigmoid(), name=\"HiddenLayer\"),\n",
        "        Dense(size=10, activation=Sigmoid(), name=\"OutputLayer\")\n",
        "    ]\n",
        "    return NeuralNetwork(\n",
        "        layers=layers,\n",
        "        batch_size=128,\n",
        "        optimizer=RMSProp,\n",
        "        initialization=\"XavierUniform\",\n",
        "        epochs=1,\n",
        "        t=t,\n",
        "        X_val=X_val_scaled,\n",
        "        t_val=t_val,\n",
        "        loss=SquaredError(),\n",
        "        use_wandb=True\n",
        "    )\n",
        "\n",
        "def train_and_evaluate(model, X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test):\n",
        "    model.train()\n",
        "    acc_val, loss_val, _ = model.check_test(X_val_scaled, t_val)\n",
        "    acc_test, loss_test, y_test_pred = model.check_test(X_test_scaled, t_test)\n",
        "\n",
        "    wandb.log({\"val_loss_end\": loss_val / t_val.shape[1],\n",
        "               \"val_acc_end\": acc_val / t_val.shape[1],\n",
        "               \"test_loss_end\": loss_test / t_test.shape[1],\n",
        "               \"test_acc_end\": acc_test / t_test.shape[1]})\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    sns.heatmap(confusion_matrix(y_test[:9000], y_test_pred), annot=True, fmt='g')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    wandb.log({\"Confusion Matrix\": plt})\n",
        "\n",
        "def train_nn(config):\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = load_data()\n",
        "    X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test = preprocess_data(\n",
        "        x_train, y_train, x_val, y_val, x_test, y_test\n",
        "    )\n",
        "    model = define_network(X_train_scaled, t_train, X_val_scaled, t_val)\n",
        "    train_and_evaluate(model, X_train_scaled, t_train, X_val_scaled, t_val, X_test_scaled, t_test)\n",
        "\n",
        "sweep_config = {\n",
        "    \"name\": \"best-sweep\",\n",
        "    \"method\": \"grid\",\n",
        "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
        "    \"parameters\": {\n",
        "        \"num_epochs\": {\"values\": [1]},\n",
        "        \"size_hidden_layer\": {\"values\": [64]},\n",
        "        \"optimizer\": {\"values\": [\"RMSProp\"]},\n",
        "        \"batch_size\": {\"values\": [128]},\n",
        "        \"weight_init\": {\"values\": [\"XavierUniform\"]},\n",
        "        \"activation\": {\"values\": [\"Sigmoid\"]},\n",
        "        \"loss\": {\"values\": [\"SquaredError\"]}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"set-1\")\n",
        "wandb.agent(sweep_id, function=train_nn)"
      ],
      "metadata": {
        "id": "POyf8gMknCDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}